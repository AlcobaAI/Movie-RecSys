{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe37cb4f-4ece-487a-9496-6f59af6b56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from tqdm.notebook import tnrange, tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3af993-aa92-4de8-ab64-4f4dde0070ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('data/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d10e49-8c89-4d28-a67f-4c47c4703af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(ratings.columns[[-1]], axis=1, inplace=True)\n",
    "\n",
    "# Get the user with at least 5 ratings\n",
    "relevant_users = ratings.groupby(\"userId\", as_index=False).agg({'movieId':len})\n",
    "relevant_users = relevant_users[relevant_users.movieId > 4].drop('movieId', axis=1)\n",
    "\n",
    "dataset = ratings.merge(relevant_users)\n",
    "\n",
    "# Get 100 most rated movies\n",
    "top_100 = ratings.movieId.value_counts()[:100].index.values\n",
    "dataset = dataset[dataset['movieId'].isin(top_100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc2e051-3d88-4a7b-bb5f-bb309c8dacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2movie = dataset.movieId.unique()\n",
    "movie2idx = {movie:idx for idx, movie in enumerate(idx2movie)}\n",
    "\n",
    "dataset['movieId'] = dataset['movieId'].apply(lambda movie: movie2idx[movie])\n",
    "\n",
    "idx2user = dataset.userId.unique()\n",
    "user2idx = {user:idx for idx, user in enumerate(idx2user)}\n",
    "\n",
    "dataset['userId'] = dataset['userId'].apply(lambda user: user2idx[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe426050-15eb-4346-9d67-0c5b9275dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "2       0        0     3.5\n",
       "3       0        1     3.5\n",
       "4       0        2     3.5\n",
       "8       0        3     4.0\n",
       "9       0        4     4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792fa179-eb2b-481a-853e-e4a914ebb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b292813d-4966-452b-b4cd-07c4cbc5b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = len(user2idx)\n",
    "nb_movies = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d61aa67-158b-4355-a692-8d25430b8390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118644c51f46425089675cab3a0270cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Convert(data):\n",
    "    new_data = []\n",
    "    for id_users in tnrange(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "ratings_matrix = Convert(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d24156d-f140-442d-9408-12c15f20958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros((len(user2idx), len(movie2idx)))\n",
    "train = np.array(ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a10a69-1dc5-4506-810f-4de209b1b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_train, user_test in zip(train, test):\n",
    "        \n",
    "        nonzero = user_train.nonzero()[0]\n",
    "        \n",
    "        # Select 20% for testing\n",
    "        size = nonzero.shape[0]//5\n",
    "        test_ratings = np.random.choice(nonzero, size=size, replace=False)\n",
    "        \n",
    "        # Keep the records for testing\n",
    "        user_test[test_ratings] = user_train[test_ratings]\n",
    "        # Zero out for training\n",
    "        user_train[test_ratings] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0634e341-e29c-442b-82d5-1400b4a6d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into Torch tensors\n",
    "train_matrix_tensor = torch.FloatTensor(train)\n",
    "test_matrix_tensor = torch.FloatTensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf1baf0-f4cf-446d-98b5-ab3d7a7b8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEnconderNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the main components of the network including the loss and optimizer.\"\"\"\n",
    "        super(AutoEnconderNN, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(nb_movies, 80),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(80, 40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(40, 80),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(80, nb_movies)\n",
    "        )\n",
    "        \n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=.01, momentum=0.9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Get hard class predictions from the \n",
    "        feature data\n",
    "        '''\n",
    "        predictions = self.forward(x)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5935bf4-5815-4687-9440-58a7d1e59a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = AutoEnconderNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(AE.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "169f8d9d-abdd-4995-af3b-9680a6ccef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_matrix_tensor, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4450415-c0c1-4ee1-bc5a-bfb924aca7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9deb664de1b4ba9b871ec4accab6139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total epochs:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: tensor(0.1007)\n",
      "epoch: 1 loss: tensor(0.0380)\n",
      "epoch: 2 loss: tensor(0.0292)\n",
      "epoch: 3 loss: tensor(0.0292)\n",
      "epoch: 4 loss: tensor(0.0292)\n",
      "epoch: 5 loss: tensor(0.0292)\n",
      "epoch: 6 loss: tensor(0.0292)\n",
      "epoch: 7 loss: tensor(0.0292)\n",
      "epoch: 8 loss: tensor(0.0292)\n",
      "epoch: 9 loss: tensor(0.0292)\n",
      "epoch: 10 loss: tensor(0.0292)\n",
      "epoch: 11 loss: tensor(0.0292)\n",
      "epoch: 12 loss: tensor(0.0292)\n",
      "epoch: 13 loss: tensor(0.0292)\n",
      "epoch: 14 loss: tensor(0.0292)\n",
      "epoch: 15 loss: tensor(0.0292)\n",
      "epoch: 16 loss: tensor(0.0292)\n",
      "epoch: 17 loss: tensor(0.0292)\n",
      "epoch: 18 loss: tensor(0.0292)\n",
      "epoch: 19 loss: tensor(0.0292)\n",
      "epoch: 20 loss: tensor(0.0292)\n",
      "epoch: 21 loss: tensor(0.0292)\n",
      "epoch: 22 loss: tensor(0.0292)\n",
      "epoch: 23 loss: tensor(0.0292)\n",
      "epoch: 24 loss: tensor(0.0291)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 25\n",
    "for epoch in tnrange(0, nb_epoch, desc=\"Total epochs: \"):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for users in train_dataloader:\n",
    "        input = Variable(users).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = AE(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805dcf1a-8670-4f13-987b-323504baab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9bf3dd51474243a547427a221f9b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.8870)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in tnrange(nb_users):\n",
    "        \n",
    "    input = Variable(test_matrix_tensor[id_user]).unsqueeze(0)\n",
    "    target = Variable(train_matrix_tensor[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = AE(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5ff969-24a8-4509-9614-05de6164a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Variable(test_matrix_tensor[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2a244ce-db53-4a27-b3a7-51a48bcfd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = Variable(train_matrix_tensor[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc6f8c6-8714-4965-baa1-a5ea37cc330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = AE(sample).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ecfa53-49b7-41b7-9563-dd0636242582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5398285"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(true_vals, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
